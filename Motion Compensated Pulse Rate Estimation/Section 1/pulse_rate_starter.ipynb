{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Pulse Rate Algorithm\n",
    "\n",
    "### Contents\n",
    "Fill out this notebook as part of your final project submission.\n",
    "\n",
    "**You will have to complete both the Code and Project Write-up sections.**\n",
    "- The [Code](#Code) is where you will write a **pulse rate algorithm** and already includes the starter code.\n",
    "   - Imports - These are the imports needed for Part 1 of the final project. \n",
    "     - [glob](https://docs.python.org/3/library/glob.html)\n",
    "     - [numpy](https://numpy.org/)\n",
    "     - [scipy](https://www.scipy.org/)\n",
    "- The [Project Write-up](#Project-Write-up) to describe why you wrote the algorithm for the specific case.\n",
    "\n",
    "\n",
    "### Dataset\n",
    "You will be using the **Troika**[1] dataset to build your algorithm. Find the dataset under `datasets/troika/training_data`. The `README` in that folder will tell you how to interpret the data. The starter code contains a function to help load these files.\n",
    "\n",
    "1. Zhilin Zhang, Zhouyue Pi, Benyuan Liu, ‘‘TROIKA: A General Framework for Heart Rate Monitoring Using Wrist-Type Photoplethysmographic Signals During Intensive Physical Exercise,’’IEEE Trans. on Biomedical Engineering, vol. 62, no. 2, pp. 522-531, February 2015. Link\n",
    "\n",
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import scipy.signal\n",
    "import glob\n",
    "\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import scipy.io\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.mlab as mlab\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "minfreq = 40/60.0\n",
    "maxfreq = 240/60.0\n",
    "\n",
    "def LoadTroikaDataset():\n",
    "    \"\"\"\n",
    "    Retrieve the .mat filenames for the troika dataset.\n",
    "\n",
    "    Review the README in ./datasets/troika/ to understand the organization of the .mat files.\n",
    "\n",
    "    Returns:\n",
    "        data_fls: Names of the .mat files that contain signal data\n",
    "        ref_fls: Names of the .mat files that contain reference data\n",
    "        <data_fls> and <ref_fls> are ordered correspondingly, so that ref_fls[5] is the \n",
    "            reference data for data_fls[5], etc...\n",
    "    \"\"\"\n",
    "    data_dir = \"./datasets/troika/training_data\"\n",
    "    data_fls = sorted(glob.glob(data_dir + \"/DATA_*.mat\"))\n",
    "    ref_fls = sorted(glob.glob(data_dir + \"/REF_*.mat\"))\n",
    "    return data_fls, ref_fls\n",
    "\n",
    "def LoadTroikaDataFile(data_fl):\n",
    "    \"\"\"\n",
    "    Loads and extracts signals from a troika data file.\n",
    "\n",
    "    Usage:\n",
    "        data_fls, ref_fls = LoadTroikaDataset()\n",
    "        ppg, accx, accy, accz = LoadTroikaDataFile(data_fls[0])\n",
    "\n",
    "    Args:\n",
    "        data_fl: (str) filepath to a troika .mat file.\n",
    "\n",
    "    Returns:\n",
    "        numpy arrays for ppg, accx, accy, accz signals.\n",
    "    \"\"\"\n",
    "    data = sp.io.loadmat(data_fl)['sig']\n",
    "    return data[2:]\n",
    "\n",
    "def AggregateErrorMetric(pr_errors, confidence_est):\n",
    "    \"\"\"\n",
    "    Computes an aggregate error metric based on confidence estimates.\n",
    "\n",
    "    Computes the MAE at 90% availability. \n",
    "\n",
    "    Args:\n",
    "        pr_errors: a numpy array of errors between pulse rate estimates and corresponding \n",
    "            reference heart rates.\n",
    "        confidence_est: a numpy array of confidence estimates for each pulse rate\n",
    "            error.\n",
    "\n",
    "    Returns:\n",
    "        the MAE at 90% availability\n",
    "    \"\"\"\n",
    "    # Higher confidence means a better estimate. The best 90% of the estimates\n",
    "    #    are above the 10th percentile confidence.\n",
    "    percentile90_confidence = np.percentile(confidence_est, 10)\n",
    "\n",
    "    # Find the errors of the best pulse rate estimates\n",
    "    best_estimates = pr_errors[confidence_est >= percentile90_confidence]\n",
    "\n",
    "    # Return the mean absolute error\n",
    "    return np.mean(np.abs(best_estimates))\n",
    "\n",
    "def Evaluate():\n",
    "    \"\"\"\n",
    "    Top-level function evaluation function.\n",
    "\n",
    "    Runs the pulse rate algorithm on the Troika dataset and returns an aggregate error metric.\n",
    "\n",
    "    Returns:\n",
    "        Pulse rate error on the Troika dataset. See AggregateErrorMetric.\n",
    "    \"\"\"\n",
    "    # Retrieve dataset files\n",
    "    data_fls, ref_fls = LoadTroikaDataset()\n",
    "    errs, confs = [], []\n",
    "    for data_fl, ref_fl in zip(data_fls, ref_fls):\n",
    "        # Run the pulse rate algorithm on each trial in the dataset\n",
    "        errors, confidence = RunPulseRateAlgorithm(data_fl, ref_fl)\n",
    "        errs.append(errors)\n",
    "        confs.append(confidence)\n",
    "        # Compute aggregate error metric\n",
    "    errs = np.hstack(errs)\n",
    "    confs = np.hstack(confs)\n",
    "    print(\"mean error\", errs.mean())\n",
    "    return AggregateErrorMetric(errs, confs)\n",
    "\n",
    "def RunPulseRateAlgorithm(data_fl, ref_fl):\n",
    "    \"\"\"\n",
    "    The algorithm uses the Power Spectral Density(PSD) estimates to select frequencies \n",
    "    with high PSDs for both PPG and Accelerometer signals. It then remove the frequencies \n",
    "    which could have been attributed by accelerometer by comaring the PPG frequency to \n",
    "    that of top three frequencies of accelerometer. \n",
    "    \n",
    "    Args: \n",
    "        data_fl: (str) filepath to a troika .mat file.\n",
    "        ref_f1: (str) filepath to a troika .mat file which contains reference heart beat estimates.\n",
    "        \n",
    "    Returns:\n",
    "        error_array: Array of absolute error.\n",
    "        conf_array: Array of confidence values for each erroe value.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Load data using LoadTroikaDataFile\n",
    "    ppg, accx, accy, accz = LoadTroikaDataFile(data_fl)\n",
    "\n",
    "    # loading the reference file\n",
    "    ground_truth = np.array(sp.io.loadmat(ref_fl)['BPM0'])\n",
    "    ground_truth = ground_truth.reshape(len(ground_truth))\n",
    "    \n",
    "    # Bandpass ppg and acc signals \n",
    "    ppg = bandpass_filter(ppg)\n",
    "    accx = bandpass_filter(accx)\n",
    "    accy = bandpass_filter(accy)\n",
    "    accz = bandpass_filter(accz)\n",
    "        \n",
    "    # Calculate Power Spectral Density estimates for each signal\n",
    "    psd_ppg, freqs_ppg = cal_spectogram(signal=ppg)\n",
    "    psd_accx, freqs_accx = cal_spectogram(signal=accx)\n",
    "    psd_accy, freqs_accy = cal_spectogram(signal=accy)\n",
    "    psd_accz, freqs_accz = cal_spectogram(signal=accz)\n",
    "    \n",
    "    \n",
    "    time_steps = psd_ppg.shape[1]\n",
    "    freqs = freqs_ppg.shape[0]\n",
    "    \n",
    "    # Sorted index value for signals \n",
    "    ppg_index = (-psd_ppg).argsort(axis=0)\n",
    "    accx_index = (-psd_accx).argsort(axis=0)\n",
    "    accy_index = (-psd_accy).argsort(axis=0)\n",
    "    accz_index = (-psd_accz).argsort(axis=0)\n",
    "\n",
    "    estimated_freq = []\n",
    "    for t in range(time_steps):\n",
    "        for freq in range(freqs):\n",
    "            \n",
    "            idx=0\n",
    "            # compare frequency values of ppg withat of acc siganls\n",
    "            # pick only those ppg frequencies which are not present in the top 3 frequencies of acc signals \n",
    "            if freq == 2:\n",
    "                estimated_freq.append(freqs_ppg[ppg_index[freq][t]])\n",
    "                break\n",
    "            elif np.all([(freqs_ppg[ppg_index[freq][t]] != freqs_ppg[accx_index[idx][t]]), \n",
    "                      (freqs_ppg[ppg_index[freq][t]] != freqs_ppg[accy_index[idx][t]]), \n",
    "                      (freqs_ppg[ppg_index[freq][t]] != freqs_ppg[accz_index[idx][t]]),\n",
    "                      (freqs_ppg[ppg_index[freq][t]] != freqs_ppg[accx_index[idx+1][t]]),\n",
    "                      (freqs_ppg[ppg_index[freq][t]] != freqs_ppg[accy_index[idx+1][t]]),\n",
    "                      (freqs_ppg[ppg_index[freq][t]] != freqs_ppg[accz_index[idx+1][t]]),\n",
    "                      (freqs_ppg[ppg_index[freq][t]] != freqs_ppg[accx_index[idx+2][t]]),\n",
    "                      (freqs_ppg[ppg_index[freq][t]] != freqs_ppg[accy_index[idx+2][t]]),\n",
    "                      (freqs_ppg[ppg_index[freq][t]] != freqs_ppg[accz_index[idx+2][t]])]):\n",
    "                estimated_freq.append(freqs_ppg[ppg_index[freq][t]])\n",
    "                break\n",
    "            \n",
    "    # claculate confidence using snr\n",
    "    confidence = []\n",
    "    for idx in range(len(estimated_freq)):\n",
    "        snr = calc_snr(ppg, estimated_freq[idx])\n",
    "        confidence.append(snr)\n",
    "            \n",
    "    pre = np.array(estimated_freq) * 60\n",
    "    \n",
    "    # absolute error \n",
    "    error_array = np.abs(ground_truth - pre)\n",
    "    \n",
    "    conf_array = np.array(confidence)\n",
    "\n",
    "\n",
    "    # Return per-estimate absolute error and confidence as a 2-tuple of numpy arrays.\n",
    "\n",
    "    return error_array, conf_array\n",
    "\n",
    "\n",
    "def bandpass_filter(signal):\n",
    "    \"\"\"\n",
    "    Bandpass filter the signal between 40 and 240 BPM\n",
    "    \n",
    "    Args: \n",
    "        signal: signal from PPG or Accelerometer\n",
    "    \n",
    "    Returns:\n",
    "        Band pass filtered signal.\n",
    "  \n",
    "    \"\"\"    \n",
    "    pass_band=(40/60.0, 240/60.0)\n",
    "    fs = 125\n",
    "    b, a = scipy.signal.butter(3, pass_band, btype='bandpass', fs=fs)\n",
    "    return scipy.signal.filtfilt(b, a, signal)\n",
    "\n",
    "def calc_snr(signal, hr_f):\n",
    "    \"\"\"\n",
    "    Calculate signal to noise ratio\n",
    "    \n",
    "    Args:\n",
    "        signal: signal from PPG\n",
    "        hr_f: heart rate frequency estimates\n",
    "        \n",
    "    Returns:\n",
    "        snr: signal to noise ratio\n",
    "    \n",
    "    \"\"\"\n",
    "    n = len(signal)*2\n",
    "    fs = 125\n",
    "    \n",
    "    #calculate the frequency of the first harmonic\n",
    "    harmonic_f = hr_f * 2\n",
    "    \n",
    "    #compute the fft\n",
    "    fft_mag = np.abs(np.fft.rfft(signal, n))\n",
    "    freqs = np.fft.rfftfreq(n, 1/fs)\n",
    "    \n",
    "    #find the frequencies that are around the heart rate and the first harmonic of the heart rate\n",
    "    window_f = 5/60\n",
    "    \n",
    "    fundamental_frequency_window = (freqs > hr_f - window_f) & (freqs < hr_f + window_f)\n",
    "    harmonic_frequency_window = (freqs > harmonic_f - window_f) & (freqs < harmonic_f + window_f)\n",
    "    \n",
    "    signal_power = np.sum(fft_mag[(fundamental_frequency_window) | (harmonic_frequency_window)])\n",
    "    noise_power = np.sum(fft_mag[-((fundamental_frequency_window) | (harmonic_frequency_window))])\n",
    "    \n",
    "    snr = signal_power / noise_power\n",
    "    \n",
    "    return snr\n",
    "    \n",
    "    \n",
    "\n",
    "def cal_spectogram(signal):\n",
    "    \"\"\"\n",
    "    Calculate Power Spectral Density estimates\n",
    "    \n",
    "    Args:\n",
    "        signal: PPG or Accelerometer signals\n",
    "    Returns:\n",
    "        psd: Power spectral density estimate\n",
    "        freqs:  frequencies for which PSDs are calculated\n",
    "    \n",
    "    \"\"\"\n",
    "    fs = 125\n",
    "    psd, freqs, t = mlab.specgram(signal, NFFT=8*fs, Fs=fs, noverlap=6*fs, pad_to=12*fs)\n",
    "    psd = psd[(freqs >= minfreq) & (freqs <= maxfreq)]\n",
    "    freqs = freqs[(freqs >= minfreq) & (freqs <= maxfreq)]\n",
    "    return psd, freqs\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:256: DeprecationWarning: numpy boolean negative, the `-` operator, is deprecated, use the `~` operator or the logical_not function instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean error 19.6074384408\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "19.499553789676362"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "### Project Write-up\n",
    "\n",
    "Answer the following prompts to demonstrate understanding of the algorithm you wrote for this specific context.\n",
    "\n",
    "> - **Code Description** - Include details so someone unfamiliar with your project will know how to run your code and use your algorithm. \n",
    "> - **Data Description** - Describe the dataset that was used to train and test the algorithm. Include its short-comings and what data would be required to build a more complete dataset.\n",
    "> - **Algorithhm Description** will include the following:\n",
    ">   - how the algorithm works\n",
    ">   - the specific aspects of the physiology that it takes advantage of\n",
    ">   - a describtion of the algorithm outputs\n",
    ">   - caveats on algorithm outputs \n",
    ">   - common failure modes\n",
    "> - **Algorithm Performance** - Detail how performance was computed (eg. using cross-validation or train-test split) and what metrics were optimized for. Include error metrics that would be relevant to users of your algorithm. Caveat your performance numbers by acknowledging how generalizable they may or may not be on different datasets.\n",
    "\n",
    "Your write-up goes here..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Code Description\n",
    "The code can be run by executing Evaluate() in a cell. There is no need to pass any parameters.\n",
    "\n",
    "###### Data Description\n",
    "A subset of TROIKA dataset was used to train and test the model. The training dataset consist of one channel of PPG signal and three axis accelerometer signals recorded  from  subjects  with  age  from  18  to  35. For  each  subject,  the  PPG  signals were  recorded  from  wrist  by  two  pulse  oximeters  with  green  LEDs  (wavelength:  515nm).  Their distance (from center to center) was 2 cm. The acceleration signal was also recorded from wrist by a three-axis  accelerometer.  Both  the  pulse  oximeter  and  the  accelerometer  were  embedded  in  a wristband.   All  signals  were  sampled  at  125  Hz. The ECG signal from this dataset was used as a reference.\n",
    "\n",
    "The dataset has limitations as to get a better estimate, we can have a dataset which also has dtat from gyroscope and magnetometer. The gyroscope measures angular velocity while the magnetometer measures absolute orientation.\n",
    "\n",
    "###### Algorithm Description and Performace\n",
    "\n",
    "The algorithm uses the Power Spectral Density(PSD) estimates to select frequencies with high PSDs for both PPG and Accelerometer signals. It then remove the frequencies which could have been attributed by accelerometer by comaring the PPG frequency to that of top three frequencies of accelerometer. \n",
    "\n",
    "The algorithm uses PPG uses blood flow in our hands to estimate signals while the accelorometer measures accelerationsignals in three axis. \n",
    "\n",
    "The algorithm outputs absoluter error and confidence. The absolute error is calculate by using reference heart beats which are derived using ECG signals. The confidence is calculated by using signal to noise ratio. The pulse rate is estimated every 2 seconds.\n",
    "\n",
    "The estimates can be distorted by noise from other factors like \n",
    "* Melanin\n",
    "* Arm movement\n",
    "* Arm position\n",
    "* Finger movement\n",
    "\n",
    "Only by accounting for above factors we can have a better estimate. In this project, we have we were able to nullify noise from accelrometer. So, the algorithm is limited in its application. We used MAE at 90% availability as our metric to measure performace. The algorithm may also fail to perform properly for datasets where there is a sudden change in heartbeats. The error rate would increase in such a scenario.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "### Next Steps\n",
    "You will now go to **Test Your Algorithm** to apply a unit test to confirm that your algorithm met the success criteria. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
